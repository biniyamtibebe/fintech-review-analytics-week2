from google_play_scraper import reviews, Sort
import pandas as pd
import os
import logging

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# App IDs
apps = {
    'CBE': 'com.combanketh.mobilebanking',
    'BOA': 'com.boa.boaMobileBanking',
    'Dashen': 'com.cr2.amolelight'
}

all_reviews = []

# Create data directory if it doesn't exist
os.makedirs('Data', exist_ok=True)

# Scrape reviews
for bank, app_id in apps.items():
    try:
        logging.info(f"Scraping reviews for {bank} (App ID: {app_id})")
        
        # Fetching reviews
        result, _ = reviews(
            app_id,
            lang='en',
            country='et',
            sort=Sort.NEWEST,
            count=500  # Adjust if needed
        )
        
        # Add bank name and source
        for review in result:
            review['bank'] = bank
            review['source'] = 'Google Play'
        
        all_reviews.extend(result)
        
        logging.info(f"Successfully collected {len(result)} reviews for {bank}.")
    
    except Exception as e:
        logging.error(f"Error occurred while scraping {bank}: {e}")

# Convert to DataFrame
df = pd.DataFrame(all_reviews)

# Validate data - check for required fields
if df.empty:
    logging.warning("No reviews collected. Exiting.")
else:
    missing_data = df[['content', 'score', 'at']].isnull().sum()
    if missing_data.any():
        logging.warning(f"Missing data detected:\n{missing_data[missing_data > 0]}")

    # Select relevant columns
    df = df[['content', 'score', 'at', 'bank', 'source']]
    df.rename(columns={'content': 'review', 'score': 'rating', 'at': 'date'}, inplace=True)

    # Save raw data
    output_path = 'Data/raw_reviews.csv'
    
    try:
        df.to_csv(output_path, index=False)
        logging.info(f"Saved collected reviews to {output_path}. Total reviews: {len(df)}.")
    except Exception as e:
        logging.error(f"Error saving data to {output_path}: {e}")